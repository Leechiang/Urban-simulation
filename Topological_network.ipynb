{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the edgelist file from csv\n",
    "london_network = nx.read_graphml(\"C:/Users/86180/Desktop/US/cw/london.graph.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "467\n"
     ]
    }
   ],
   "source": [
    "print(london_network.number_of_nodes())\n",
    "print(london_network.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Wembley Park',\n",
       "  'Kingsbury',\n",
       "  {'length': 2916.7715580506483, 'line_name': 'Jubilee', 'flows': 12356}),\n",
       " ('Wembley Park',\n",
       "  'Neasden',\n",
       "  {'length': 2353.1659381957816, 'line_name': 'Jubilee', 'flows': 6744}),\n",
       " ('Wembley Park',\n",
       "  'Preston Road',\n",
       "  {'length': 1419.7351657633037, 'line_name': 'Metropolitan', 'flows': 36601}),\n",
       " ('Wembley Park',\n",
       "  'Finchley Road',\n",
       "  {'length': 7266.37392749648, 'line_name': 'Metropolitan', 'flows': 55216}),\n",
       " ('Kingsbury',\n",
       "  'Queensbury',\n",
       "  {'length': 1245.9952343630068, 'line_name': 'Jubilee', 'flows': 9419}),\n",
       " ('Queensbury',\n",
       "  'Canons Park',\n",
       "  {'length': 1693.307343195774, 'line_name': 'Jubilee', 'flows': 6385}),\n",
       " ('Canons Park',\n",
       "  'Stanmore',\n",
       "  {'length': 1419.6694762456716, 'line_name': 'Jubilee', 'flows': 3624}),\n",
       " ('Stratford',\n",
       "  'West Ham',\n",
       "  {'length': 1673.509515131191, 'line_name': 'Jubilee', 'flows': 91801}),\n",
       " ('Stratford',\n",
       "  'Mile End',\n",
       "  {'length': 2805.0013918567865, 'line_name': 'Central', 'flows': 12010}),\n",
       " ('Stratford',\n",
       "  'Leyton',\n",
       "  {'length': 2131.342925924046, 'line_name': 'Central', 'flows': 56082})]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check edges attributes:\n",
    "list(london_network.edges(data = True))[0:10]\n",
    "\n",
    "# Other way to do it: \n",
    "# list(g_dad.edges.data())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us compute the degree centrality\n",
    "deg_london_network=nx.degree_centrality(london_network)\n",
    "nx.set_node_attributes(london_network,dict(deg_london_network),'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stratford</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank and Monument</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King's Cross St. Pancras</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baker Street</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earl's Court</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oxford Circus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liverpool Street</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterloo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Green Park</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canning Town</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         station_name  degree\n",
       "Stratford                         NaN  0.0225\n",
       "Bank and Monument                 NaN  0.0200\n",
       "King's Cross St. Pancras          NaN  0.0175\n",
       "Baker Street                      NaN  0.0175\n",
       "Earl's Court                      NaN  0.0150\n",
       "Oxford Circus                     NaN  0.0150\n",
       "Liverpool Street                  NaN  0.0150\n",
       "Waterloo                          NaN  0.0150\n",
       "Green Park                        NaN  0.0150\n",
       "Canning Town                      NaN  0.0150"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To dataframe using the nodes as the index\n",
    "df = pd.DataFrame(index=london_network.nodes())\n",
    "df['station_name'] = pd.Series(nx.get_node_attributes(london_network,'station_name'))\n",
    "df['degree'] = pd.Series(nx.get_node_attributes(london_network, 'degree'))\n",
    "\n",
    "df_sorted = df.sort_values([\"degree\"], ascending=False)\n",
    "df_sorted[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closeness_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Green Park</th>\n",
       "      <td>0.114778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank and Monument</th>\n",
       "      <td>0.113572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King's Cross St. Pancras</th>\n",
       "      <td>0.113443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westminster</th>\n",
       "      <td>0.112549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterloo</th>\n",
       "      <td>0.112265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oxford Circus</th>\n",
       "      <td>0.111204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bond Street</th>\n",
       "      <td>0.110988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Farringdon</th>\n",
       "      <td>0.110742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angel</th>\n",
       "      <td>0.110742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moorgate</th>\n",
       "      <td>0.110314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          closeness_w\n",
       "Green Park                   0.114778\n",
       "Bank and Monument            0.113572\n",
       "King's Cross St. Pancras     0.113443\n",
       "Westminster                  0.112549\n",
       "Waterloo                     0.112265\n",
       "Oxford Circus                0.111204\n",
       "Bond Street                  0.110988\n",
       "Farringdon                   0.110742\n",
       "Angel                        0.110742\n",
       "Moorgate                     0.110314"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topological closeness centrality\n",
    "clos_w=nx.closeness_centrality(london_network)\n",
    "# We can add these values to the nodes attributes:\n",
    "nx.set_node_attributes(london_network,clos_w,'closeness_w')\n",
    "\n",
    "# To ataframe using the nodes as the index\n",
    "df = pd.DataFrame(index=london_network.nodes())\n",
    "df['closeness_w'] = pd.Series(nx.get_node_attributes(london_network, 'closeness_w'))\n",
    "\n",
    "df_sorted = df.sort_values([\"closeness_w\"], ascending=False)\n",
    "df_sorted[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>betweenness_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stratford</th>\n",
       "      <td>23768.093434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank and Monument</th>\n",
       "      <td>23181.058947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liverpool Street</th>\n",
       "      <td>21610.387049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>King's Cross St. Pancras</th>\n",
       "      <td>20373.521465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waterloo</th>\n",
       "      <td>19464.882323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Green Park</th>\n",
       "      <td>17223.622114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euston</th>\n",
       "      <td>16624.275469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westminster</th>\n",
       "      <td>16226.155916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baker Street</th>\n",
       "      <td>15287.107612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finchley Road</th>\n",
       "      <td>13173.758009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          betweenness_w\n",
       "Stratford                  23768.093434\n",
       "Bank and Monument          23181.058947\n",
       "Liverpool Street           21610.387049\n",
       "King's Cross St. Pancras   20373.521465\n",
       "Waterloo                   19464.882323\n",
       "Green Park                 17223.622114\n",
       "Euston                     16624.275469\n",
       "Westminster                16226.155916\n",
       "Baker Street               15287.107612\n",
       "Finchley Road              13173.758009"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us compute the betweenness centrality for the network, considering the distance between stations:\n",
    "\n",
    "bet_london_w=nx.betweenness_centrality(london_network,normalized=False)\n",
    "\n",
    "# We can add these values to the nodes attributes:\n",
    "nx.set_node_attributes(london_network,bet_london_w,'betweenness_w')\n",
    "# To dataframe using the nodes as the index\n",
    "df = pd.DataFrame(index=london_network.nodes())\n",
    "df['betweenness_w'] = pd.Series(nx.get_node_attributes(london_network, 'betweenness_w'))\n",
    "\n",
    "df_sorted = df.sort_values([\"betweenness_w\"], ascending=False)\n",
    "df_sorted[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_networkRN=london_network.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Efficiency before removal: 0.1012561935972123\n"
     ]
    }
   ],
   "source": [
    "# 计算删除节点前的全局效率\n",
    "global_efficiency_before_removal = nx.global_efficiency(london_networkRN)\n",
    "print(\"Global Efficiency before removal:\", global_efficiency_before_removal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closness centrality 10 nodes (Non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing node Green Park, Global Efficiency: 0.09918991960788402\n",
      "After removing node Bank and Monument, Global Efficiency: 0.09487232544791133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing node King's Cross St. Pancras, Global Efficiency: 0.08793385149140875\n",
      "After removing node Westminster, Global Efficiency: 0.08737164566976727\n",
      "After removing node Waterloo, Global Efficiency: 0.08485943799789313\n",
      "After removing node Oxford Circus, Global Efficiency: 0.08278135073141742\n",
      "After removing node Bond Street, Global Efficiency: 0.08258086417012774\n",
      "After removing node Farringdon, Global Efficiency: 0.08260040537396239\n",
      "After removing node Angel, Global Efficiency: 0.08262233108950982\n",
      "After removing node Moorgate, Global Efficiency: 0.08166991436767818\n"
     ]
    }
   ],
   "source": [
    "# To remove  10 highest values:\n",
    "# List of nodes:\n",
    "values_sorted = sorted(clos_w.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_ten=[e for e,v in values_sorted[:10]]\n",
    "sorted_ten\n",
    "# 要删除的节点列表\n",
    "CCnodes_to_remove = sorted_ten\n",
    "london_networkCCRN10 = london_network.copy()\n",
    "for node in CCnodes_to_remove:\n",
    "    london_networkCCRN10.remove_node(node)\n",
    "    global_efficiency_after = nx.global_efficiency(london_networkCCRN10)\n",
    "    print(f\"After removing node {node}, Global Efficiency: {global_efficiency_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest component of closeness centrality (Non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除节点 Green Park 后的最大连通分量大小为 400\n",
      "移除节点 Bank and Monument 后的最大连通分量大小为 399\n",
      "移除节点 King's Cross St. Pancras 后的最大连通分量大小为 398\n",
      "移除节点 Westminster 后的最大连通分量大小为 397\n",
      "移除节点 Waterloo 后的最大连通分量大小为 396\n",
      "移除节点 Oxford Circus 后的最大连通分量大小为 395\n",
      "移除节点 Bond Street 后的最大连通分量大小为 394\n",
      "移除节点 Farringdon 后的最大连通分量大小为 393\n",
      "移除节点 Angel 后的最大连通分量大小为 392\n",
      "移除节点 Moorgate 后的最大连通分量大小为 389\n"
     ]
    }
   ],
   "source": [
    "# 移除 closeness centrality 最高的前十个节点，并计算最大连通分量\n",
    "def remove_top_closeness_centrality_nodes(london_network1, closeness_centrality):\n",
    "    # 根据 closeness centrality 排序节点，并取前十个节点\n",
    "    sorted_nodes = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    # 获取要移除的节点列表\n",
    "    nodes_to_remove = [node for node, _ in sorted_nodes]\n",
    "    # 创建图的副本\n",
    "    london_network1_copy = london_network.copy()\n",
    "    # 存储结果\n",
    "    results = []\n",
    "    # 逐个移除节点并计算最大连通分量\n",
    "    for node in nodes_to_remove:\n",
    "        london_network1_copy.remove_node(node)\n",
    "        # 计算最大连通分量\n",
    "        components = nx.connected_components(london_network1_copy)\n",
    "        largest_component = max(components, key=len)\n",
    "        # 存储结果\n",
    "        results.append({'Removed_Node': node, 'Largest_Component_Size_After_Removal': len(largest_component)})\n",
    "        print(\"移除节点\", node, \"后的最大连通分量大小为\", len(largest_component))\n",
    "    return results\n",
    "\n",
    "# 示例用法\n",
    "# 假设您已经计算了 closeness centrality 并将其存储在 clos_w 中\n",
    "\n",
    "# 创建图的副本\n",
    "london_network1_copy = london_network.copy()\n",
    "\n",
    "# 移除 closeness centrality 最高的前十个节点，并计算最大连通分量\n",
    "result = remove_top_closeness_centrality_nodes(london_network1_copy, clos_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality 10 nodes (Non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing node Stratford, Global Efficiency: 0.08891736066510689\n",
      "After removing node Bank and Monument, Global Efficiency: 0.08586164448742485\n",
      "After removing node Baker Street, Global Efficiency: 0.08203328759057034\n",
      "After removing node King's Cross St. Pancras, Global Efficiency: 0.07570039409751211\n",
      "After removing node West Ham, Global Efficiency: 0.07302243396164704\n",
      "After removing node Canning Town, Global Efficiency: 0.06893502024058405\n",
      "After removing node Waterloo, Global Efficiency: 0.06721932836875794\n",
      "After removing node Green Park, Global Efficiency: 0.06622091057392582\n",
      "After removing node Oxford Circus, Global Efficiency: 0.06536196059296152\n",
      "After removing node Liverpool Street, Global Efficiency: 0.06373592086177943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To remove  10 highest values:\n",
    "# List of nodes:\n",
    "values_sorted = sorted(deg_london_network.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_ten=[e for e,v in values_sorted[:10]]\n",
    "sorted_ten\n",
    "# 要删除的节点列表\n",
    "DCnodes_to_remove = sorted_ten\n",
    "london_networkDCRN10 = london_network.copy()\n",
    "for node in DCnodes_to_remove:\n",
    "    london_networkDCRN10.remove_node(node)\n",
    "    global_efficiency_after = nx.global_efficiency(london_networkDCRN10)\n",
    "    print(f\"After removing node {node}, Global Efficiency: {global_efficiency_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest component of degree centrality (Non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除节点 Stratford 后的最大连通分量大小为 379\n",
      "移除节点 Bank and Monument 后的最大连通分量大小为 378\n",
      "移除节点 Baker Street 后的最大连通分量大小为 377\n",
      "移除节点 King's Cross St. Pancras 后的最大连通分量大小为 374\n",
      "移除节点 West Ham 后的最大连通分量大小为 371\n",
      "移除节点 Canning Town 后的最大连通分量大小为 356\n",
      "移除节点 Waterloo 后的最大连通分量大小为 355\n",
      "移除节点 Green Park 后的最大连通分量大小为 354\n",
      "移除节点 Oxford Circus 后的最大连通分量大小为 352\n",
      "移除节点 Liverpool Street 后的最大连通分量大小为 346\n"
     ]
    }
   ],
   "source": [
    "# 移除 degree centrality 最高的前十个节点，并计算最大连通分量\n",
    "def remove_top_degree_centrality_nodes(london_network, degree_centrality):\n",
    "    # 根据 degree centrality 排序节点，并取前十个节点\n",
    "    sorted_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    # 获取要移除的节点列表\n",
    "    nodes_to_remove = [node for node, _ in sorted_nodes]\n",
    "    # 创建图的副本\n",
    "    london_networkdlc_copy = london_network.copy()\n",
    "    # 存储结果\n",
    "    results = []\n",
    "    # 逐个移除节点并计算最大连通分量\n",
    "    for node in nodes_to_remove:\n",
    "        london_networkdlc_copy.remove_node(node)\n",
    "        # 计算最大连通分量\n",
    "        components = nx.connected_components(london_networkdlc_copy)\n",
    "        largest_component = max(components, key=len)\n",
    "        # 存储结果\n",
    "        results.append({'Removed_Node': node, 'Largest_Component_Size_After_Removal': len(largest_component)})\n",
    "        print(\"移除节点\", node, \"后的最大连通分量大小为\", len(largest_component))\n",
    "    return results\n",
    "\n",
    "# 示例用法\n",
    "# 假设您已经计算了 degree centrality 并将其存储在 deg_london_network 中\n",
    "\n",
    "# 创建图的副本\n",
    "london_networkdlc_copy = london_network.copy()\n",
    "\n",
    "# 移除 closeness centrality 最高的前十个节点，并计算最大连通分量\n",
    "result = remove_top_degree_centrality_nodes(london_networkdlc_copy, deg_london_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness centrality 10 nodes (Non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing node Stratford, Global Efficiency: 0.08891736066510689\n",
      "After removing node Bank and Monument, Global Efficiency: 0.08586164448742485\n",
      "After removing node Liverpool Street, Global Efficiency: 0.08496349266423939\n",
      "After removing node King's Cross St. Pancras, Global Efficiency: 0.07849775440713821\n",
      "After removing node Waterloo, Global Efficiency: 0.07594226578366223\n",
      "After removing node Green Park, Global Efficiency: 0.07415154167648695\n",
      "After removing node Euston, Global Efficiency: 0.06820564659789057\n",
      "After removing node Westminster, Global Efficiency: 0.06765950327361094\n",
      "After removing node Baker Street, Global Efficiency: 0.064700058053009\n",
      "After removing node Finchley Road, Global Efficiency: 0.06313903700825897\n"
     ]
    }
   ],
   "source": [
    "# To remove  10 highest values:\n",
    "# List of nodes:\n",
    "values_sorted = sorted(bet_london_w.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_ten=[e for e,v in values_sorted[:10]]\n",
    "sorted_ten\n",
    "# 要删除的节点列表\n",
    "BCnodes_to_remove = sorted_ten\n",
    "london_networkBCRN10 = london_network.copy()\n",
    "for node in BCnodes_to_remove:\n",
    "    london_networkBCRN10.remove_node(node)\n",
    "    global_efficiency_after = nx.global_efficiency(london_networkBCRN10)\n",
    "    print(f\"After removing node {node}, Global Efficiency: {global_efficiency_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest component of betweenness centrality (Non-sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移除节点 Stratford 后的最大连通分量大小为 379\n",
      "移除节点 Bank and Monument 后的最大连通分量大小为 378\n",
      "移除节点 Liverpool Street 后的最大连通分量大小为 377\n",
      "移除节点 King's Cross St. Pancras 后的最大连通分量大小为 371\n",
      "移除节点 Waterloo 后的最大连通分量大小为 370\n",
      "移除节点 Green Park 后的最大连通分量大小为 369\n",
      "移除节点 Euston 后的最大连通分量大小为 346\n",
      "移除节点 Westminster 后的最大连通分量大小为 345\n",
      "移除节点 Baker Street 后的最大连通分量大小为 342\n",
      "移除节点 Finchley Road 后的最大连通分量大小为 339\n"
     ]
    }
   ],
   "source": [
    "# 移除 betweenness centrality 最高的前十个节点，并计算最大连通分量\n",
    "def remove_top_betweenness_centrality_nodes(london_network, betweenness_centrality):\n",
    "    # 根据 betweenness centrality 排序节点，并取前十个节点\n",
    "    sorted_nodes = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    # 获取要移除的节点列表\n",
    "    nodes_to_remove = [node for node, _ in sorted_nodes]\n",
    "    # 创建图的副本\n",
    "    london_networkblc_copy = london_network.copy()\n",
    "    # 存储结果\n",
    "    results = []\n",
    "    # 逐个移除节点并计算最大连通分量\n",
    "    for node in nodes_to_remove:\n",
    "        london_networkblc_copy.remove_node(node)\n",
    "        # 计算最大连通分量\n",
    "        components = nx.connected_components(london_networkblc_copy)\n",
    "        largest_component = max(components, key=len)\n",
    "        # 存储结果\n",
    "        results.append({'Removed_Node': node, 'Largest_Component_Size_After_Removal': len(largest_component)})\n",
    "        print(\"移除节点\", node, \"后的最大连通分量大小为\", len(largest_component))\n",
    "    return results\n",
    "\n",
    "# 示例用法\n",
    "# 假设您已经计算了 degree centrality 并将其存储在 deg_london_network 中\n",
    "\n",
    "# 创建图的副本\n",
    "london_networkblc_copy = london_network.copy()\n",
    "\n",
    "# 移除 closeness centrality 最高的前十个节点，并计算最大连通分量\n",
    "result = remove_top_degree_centrality_nodes(london_networkblc_copy, bet_london_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove one node （Sequential）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_networkBRN1 = london_network.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global efficiency on removing 10 node gradually (betweenness) （Sequential）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除节点 Stratford 后，全局效率为：0.08891736066510689，加权直径为：49，最大连通分量大小为：379\n",
      "删除节点 King's Cross St. Pancras 后，全局效率为：0.08460293133575152，加权直径为：49，最大连通分量大小为：378\n",
      "删除节点 Waterloo 后，全局效率为：0.08182895253292936，加权直径为：49，最大连通分量大小为：377\n",
      "删除节点 Bank and Monument 后，全局效率为：0.07767794342812263，加权直径为：49，最大连通分量大小为：376\n",
      "删除节点 Canada Water 后，全局效率为：0.07283234083472483，加权直径为：55，最大连通分量大小为：375\n",
      "删除节点 West Hampstead 后，全局效率为：0.053210203984026455，加权直径为：38，最大连通分量大小为：227\n",
      "删除节点 Earl's Court 后，全局效率为：0.05165629952389727，加权直径为：39，最大连通分量大小为：226\n",
      "删除节点 Shepherd's Bush 后，全局效率为：0.0458442134055722，加权直径为：37，最大连通分量大小为：196\n",
      "删除节点 Euston 后，全局效率为：0.04163076968121037，加权直径为：38，最大连通分量大小为：173\n",
      "删除节点 Baker Street 后，全局效率为：0.0381637040943985，加权直径为：48，最大连通分量大小为：170\n"
     ]
    }
   ],
   "source": [
    "# 删除节点并计算全局效率的函数\n",
    "def remove_node_and_calculate_efficiency(london_networkBRN1, node):\n",
    "    london_networkBRN1_copy = london_networkBRN1.copy()\n",
    "    london_networkBRN1_copy.remove_node(node)\n",
    "    global_efficiency_after = nx.global_efficiency(london_networkBRN1_copy)\n",
    "    # 计算最大连通分量\n",
    "    largest_cc = max(nx.connected_components(london_networkBRN1_copy), key=len)\n",
    "    largest_component_size = len(largest_cc)\n",
    "    return london_networkBRN1_copy, global_efficiency_after, largest_component_size\n",
    "\n",
    "# 计算加权距离的直径的函数\n",
    "def calculate_weighted_diameter(london_networkBRN1):\n",
    "    # 寻找最大的连通分量\n",
    "    largest_cc = max(nx.connected_components(london_networkBRN1), key=len)\n",
    "    # 在最大的连通分量上计算直径\n",
    "    london_networkBRN1_largest_cc = london_networkBRN1.subgraph(largest_cc).copy()\n",
    "    nlen = {n: nx.single_source_dijkstra_path_length(london_networkBRN1_largest_cc, n) for n in london_networkBRN1_largest_cc.nodes()}\n",
    "    e = nx.eccentricity(london_networkBRN1_largest_cc, sp=nlen)\n",
    "    d = nx.diameter(london_networkBRN1_largest_cc, e)\n",
    "    return d\n",
    "\n",
    "# 删除基于介数中心性的前10个节点并计算全局效率和直径\n",
    "london_networkBRN10G = london_networkBRN1.copy()\n",
    "for i in range(10):\n",
    "    # 计算介数中心性并排序节点\n",
    "    betweenness_centrality = nx.betweenness_centrality(london_networkBRN10G, normalized=False)\n",
    "    sorted_nodes = sorted(betweenness_centrality.items(), key=itemgetter(1), reverse=True)\n",
    "    # 选择要删除的节点\n",
    "    node_to_remove = sorted_nodes[0][0]\n",
    "    # 删除节点并计算全局效率和最大连通分量\n",
    "    london_networkBRN10G, global_efficiency_after, largest_component_size = remove_node_and_calculate_efficiency(london_networkBRN10G, node_to_remove)\n",
    "    # 计算加权直径\n",
    "    weighted_diameter = calculate_weighted_diameter(london_networkBRN10G)\n",
    "    print(f\"删除节点 {node_to_remove} 后，全局效率为：{global_efficiency_after}，加权直径为：{weighted_diameter}，最大连通分量大小为：{largest_component_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global efficiency on removing 10 node gradually (degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_networkDRN1 = london_network.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除节点 Stratford 后，全局效率为：0.08891736066510689，加权直径为：49，最大连通分量大小为：379\n",
      "删除节点 Bank and Monument 后，全局效率为：0.08586164448742485，加权直径为：49，最大连通分量大小为：378\n",
      "删除节点 Baker Street 后，全局效率为：0.08203328759057034，加权直径为：49，最大连通分量大小为：377\n",
      "删除节点 King's Cross St. Pancras 后，全局效率为：0.07570039409751211，加权直径为：49，最大连通分量大小为：374\n",
      "删除节点 Canning Town 后，全局效率为：0.07039592695635104，加权直径为：50，最大连通分量大小为：360\n",
      "删除节点 Green Park 后，全局效率为：0.06940235301523284，加权直径为：51，最大连通分量大小为：359\n",
      "删除节点 Earl's Court 后，全局效率为：0.0677717604548151，加权直径为：51，最大连通分量大小为：358\n",
      "删除节点 Waterloo 后，全局效率为：0.06593580277595987，加权直径为：51，最大连通分量大小为：357\n",
      "删除节点 Oxford Circus 后，全局效率为：0.06506900122239155，加权直径为：51，最大连通分量大小为：355\n",
      "删除节点 Willesden Junction 后，全局效率为：0.056747518813518014，加权直径为：60，最大连通分量大小为：341\n"
     ]
    }
   ],
   "source": [
    "# 删除节点并计算全局效率的函数\n",
    "def remove_node_and_calculate_efficiency(london_networkDRN1, node):\n",
    "    london_networkDRN1_copy = london_networkDRN1.copy()\n",
    "    london_networkDRN1_copy.remove_node(node)\n",
    "    global_efficiency_after = nx.global_efficiency(london_networkDRN1_copy)\n",
    "    # 计算最大连通分量\n",
    "    largest_cc = max(nx.connected_components(london_networkDRN1_copy), key=len)\n",
    "    largest_component_size = len(largest_cc)\n",
    "    return london_networkDRN1_copy, global_efficiency_after, largest_component_size\n",
    "\n",
    "# 计算加权距离的直径的函数\n",
    "def calculate_weighted_diameter(london_networkDRN1):\n",
    "    # 寻找最大的连通分量\n",
    "    largest_cc = max(nx.connected_components(london_networkDRN1), key=len)\n",
    "    # 在最大的连通分量上计算直径\n",
    "    london_networkDRN1_largest_cc = london_networkDRN1.subgraph(largest_cc).copy()\n",
    "    nlen = {n: nx.single_source_dijkstra_path_length(london_networkDRN1_largest_cc, n) for n in london_networkDRN1_largest_cc.nodes()}\n",
    "    e = nx.eccentricity(london_networkDRN1_largest_cc, sp=nlen)\n",
    "    d = nx.diameter(london_networkDRN1_largest_cc, e)\n",
    "    return d\n",
    "\n",
    "# 删除基于介数中心性的前10个节点并计算全局效率和直径\n",
    "london_networkDRN10G = london_networkDRN1.copy()\n",
    "for i in range(10):\n",
    "    # 计算介数中心性并排序节点\n",
    "    degree_centrality = nx.degree_centrality(london_networkDRN10G)\n",
    "    sorted_nodes = sorted(degree_centrality.items(), key=itemgetter(1), reverse=True)\n",
    "    # 选择要删除的节点\n",
    "    node_to_remove = sorted_nodes[0][0]\n",
    "    # 删除节点并计算全局效率和最大连通分量\n",
    "    london_networkDRN10G, global_efficiency_after, largest_component_size = remove_node_and_calculate_efficiency(london_networkDRN10G, node_to_remove)\n",
    "    # 计算加权直径\n",
    "    weighted_diameter = calculate_weighted_diameter(london_networkDRN10G)\n",
    "    print(f\"删除节点 {node_to_remove} 后，全局效率为：{global_efficiency_after}，加权直径为：{weighted_diameter}，最大连通分量大小为：{largest_component_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_networkCCRN1 = london_network.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global efficiency on removing 10 node gradually (closeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除节点 Green Park 后，全局效率为：0.09918991960788402，加权直径为：36，最大连通分量大小为：400\n",
      "删除节点 King's Cross St. Pancras 后，全局效率为：0.09443475025566316，加权直径为：38，最大连通分量大小为：399\n",
      "删除节点 Waterloo 后，全局效率为：0.09181648060183005，加权直径为：40，最大连通分量大小为：398\n",
      "删除节点 Bank and Monument 后，全局效率为：0.08542563066911478，加权直径为：42，最大连通分量大小为：397\n",
      "删除节点 West Hampstead 后，全局效率为：0.08054424756502003，加权直径为：50，最大连通分量大小为：396\n",
      "删除节点 Canada Water 后，全局效率为：0.05810104159173278，加权直径为：38，最大连通分量大小为：226\n",
      "删除节点 Stratford 后，全局效率为：0.051883620553389555，加权直径为：38，最大连通分量大小为：226\n",
      "删除节点 Earl's Court 后，全局效率为：0.05035000093626794，加权直径为：39，最大连通分量大小为：225\n",
      "删除节点 Shepherd's Bush 后，全局效率为：0.04439458727102797，加权直径为：40，最大连通分量大小为：195\n",
      "删除节点 Oxford Circus 后，全局效率为：0.04295771061337044，加权直径为：40，最大连通分量大小为：194\n"
     ]
    }
   ],
   "source": [
    "# 删除节点并计算全局效率的函数\n",
    "def remove_node_and_calculate_efficiency(london_networkCCRN1, node):\n",
    "    london_networkCCRN1_copy = london_networkCCRN1.copy()\n",
    "    london_networkCCRN1_copy.remove_node(node)\n",
    "    global_efficiency_after = nx.global_efficiency(london_networkCCRN1_copy)\n",
    "    # 计算最大连通分量\n",
    "    largest_cc = max(nx.connected_components(london_networkCCRN1_copy), key=len)\n",
    "    largest_component_size = len(largest_cc)\n",
    "    return london_networkCCRN1_copy, global_efficiency_after, largest_component_size\n",
    "\n",
    "# 计算加权距离的直径的函数\n",
    "def calculate_weighted_diameter(london_networkCCRN1):\n",
    "    # 寻找最大的连通分量\n",
    "    largest_cc = max(nx.connected_components(london_networkCCRN1), key=len)\n",
    "    # 在最大的连通分量上计算直径\n",
    "    london_networkCCRN1_largest_cc = london_networkCCRN1.subgraph(largest_cc).copy()\n",
    "    nlen = {n: nx.single_source_dijkstra_path_length(london_networkCCRN1_largest_cc, n) for n in london_networkCCRN1_largest_cc.nodes()}\n",
    "    e = nx.eccentricity(london_networkCCRN1_largest_cc, sp=nlen)\n",
    "    d = nx.diameter(london_networkCCRN1_largest_cc, e)\n",
    "    return d\n",
    "\n",
    "# 删除基于介数中心性的前10个节点并计算全局效率和直径\n",
    "london_networkCCRN10G = london_networkCCRN1.copy()\n",
    "for i in range(10):\n",
    "    # 计算介数中心性并排序节点\n",
    "    closeness_centrality = nx.closeness_centrality(london_networkCCRN10G)\n",
    "    sorted_nodes = sorted(closeness_centrality.items(), key=itemgetter(1), reverse=True)\n",
    "    # 选择要删除的节点\n",
    "    node_to_remove = sorted_nodes[0][0]\n",
    "    # 删除节点并计算全局效率和最大连通分量\n",
    "    london_networkCCRN10G, global_efficiency_after, largest_component_size = remove_node_and_calculate_efficiency(london_networkCCRN10G, node_to_remove)\n",
    "    # 计算加权直径\n",
    "    weighted_diameter = calculate_weighted_diameter(london_networkCCRN10G)\n",
    "    print(f\"删除节点 {node_to_remove} 后，全局效率为：{global_efficiency_after}，加权直径为：{weighted_diameter}，最大连通分量大小为：{largest_component_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
